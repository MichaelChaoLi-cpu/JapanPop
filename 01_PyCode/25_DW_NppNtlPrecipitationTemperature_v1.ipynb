{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get NPP from MYD MOD17AHGF\n",
    "\n",
    "year: 2001 - 2020\n",
    "\n",
    "Point: Japanese 4rd time Mesh 0.5 km centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NNP Extraction\n",
    "Net Primary Productivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "import os\n",
    "import glob\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#year = 2015\n",
    "aimFolder = \"F:/17_Article/01_Data/02_NetPrimaryProductivity\"\n",
    "os.mkdir(aimFolder + \"\\\\temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeAndResampleNppRaster(year, aimFolder):\n",
    "    #\"\"\"\n",
    "    #Merge MOD and MYD,\n",
    "    #Resample the raster with 0.004 degrees\n",
    "    #\"\"\"\n",
    "    rasterFile = glob.glob(\"F:/17_Article/01_Data/02_NetPrimaryProductivity/Net_PP_Yearly_500m_v6/Npp/*\"+str(year) +\"_001.tif\")\n",
    "\n",
    "    if year > 2001:\n",
    "        tifflayer_0 = gdal.Open(rasterFile[0], gdal.GA_ReadOnly)\n",
    "        tifflayer_1 = gdal.Open(rasterFile[1], gdal.GA_ReadOnly)\n",
    "\n",
    "        nband = 1\n",
    "        geotransform = tifflayer_0.GetGeoTransform()\n",
    "        spatialreference = tifflayer_0.GetProjection()\n",
    "\n",
    "        tifflayer_0_array = tifflayer_0.ReadAsArray()\n",
    "        tifflayer_0_array = np.array(tifflayer_0_array)\n",
    "        tifflayer_0_array = tifflayer_0_array.astype(float)\n",
    "        tifflayer_0_array[tifflayer_0_array == 65535] = np.nan\n",
    "        tifflayer_0_array[tifflayer_0_array > 32760] = 0\n",
    "\n",
    "        tifflayer_1_array = tifflayer_1.ReadAsArray()\n",
    "        tifflayer_1_array = np.array(tifflayer_1_array)\n",
    "        tifflayer_1_array = tifflayer_1_array.astype(float)\n",
    "        tifflayer_1_array[tifflayer_1_array == 65535] = np.nan\n",
    "        tifflayer_1_array[tifflayer_1_array > 32760] = 0\n",
    "\n",
    "        tifflayer_double_array = np.array([tifflayer_0_array, tifflayer_1_array])\n",
    "        tifflayer_mean_array = np.nanmean(tifflayer_double_array, axis = 0)\n",
    "    else:\n",
    "        tifflayer_0 = gdal.Open(rasterFile[0], gdal.GA_ReadOnly)\n",
    "\n",
    "        nband = 1\n",
    "        geotransform = tifflayer_0.GetGeoTransform()\n",
    "        spatialreference = tifflayer_0.GetProjection()\n",
    "\n",
    "        tifflayer_0_array = tifflayer_0.ReadAsArray()\n",
    "        tifflayer_0_array = np.array(tifflayer_0_array)\n",
    "        tifflayer_0_array = tifflayer_0_array.astype(float)\n",
    "        tifflayer_0_array[tifflayer_0_array == 65535] = np.nan\n",
    "        tifflayer_0_array[tifflayer_0_array > 32760] = 0\n",
    "        tifflayer_mean_array = tifflayer_0_array \n",
    "\n",
    "\n",
    "    ncol = tifflayer_mean_array.shape[1]\n",
    "    nrow = tifflayer_mean_array.shape[0]\n",
    "\n",
    "    temp_file = aimFolder + \"/temp/temp_file_\" + str(year) + \".tif\"\n",
    "\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    dst_dataset = driver.Create(temp_file, ncol, nrow, nband, gdal.GDT_Float32)\n",
    "    dst_dataset.SetGeoTransform(geotransform)\n",
    "    dst_dataset.SetProjection(spatialreference)\n",
    "    dst_dataset.GetRasterBand(1).WriteArray(tifflayer_mean_array)\n",
    "    dst_dataset = None\n",
    "\n",
    "    original_temp_raster = gdal.Open(temp_file, gdal.GA_ReadOnly)\n",
    "    raster_rprj = gdal.Warp(aimFolder + \"/temp/temp_file_\" + str(year) + \"0008.tif\", original_temp_raster, dstSRS = \"EPSG:4326\", \n",
    "                            xRes = 0.004, yRes = 0.004, resampleAlg = \"average\")\n",
    "    original_temp_raster = None\n",
    "    raster_rprj = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"d:\\Anaconda3\\envs\\Usegdal\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 436, in _process_worker\n    r = call_item()\n  File \"d:\\Anaconda3\\envs\\Usegdal\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 288, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"d:\\Anaconda3\\envs\\Usegdal\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"d:\\Anaconda3\\envs\\Usegdal\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"d:\\Anaconda3\\envs\\Usegdal\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\li.chao.987@s.kyushu-u.ac.jp\\AppData\\Local\\Temp\\ipykernel_17544\\3919920049.py\", line 9, in mergeAndResampleNppRaster\nIndexError: list index out of range\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17544\\1816829750.py\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmergeAndResampleNppRaster\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maimFolder\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0myear\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2020\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Anaconda3\\envs\\Usegdal\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\envs\\Usegdal\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\envs\\Usegdal\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\envs\\Usegdal\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    444\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\envs\\Usegdal\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m                 \u001b[1;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "Parallel(n_jobs=10)(delayed(mergeAndResampleNppRaster)(int(year), aimFolder) for year in np.linspace(2002, 2020, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2001., 2002., 2003., 2004., 2005., 2006., 2007., 2008., 2009.,\n",
       "       2010., 2011., 2012., 2013., 2014., 2015., 2016., 2017., 2018.,\n",
       "       2019., 2020.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(2001, 2020, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_extration = gpd.read_file(\"F:/17_Article/01_Data/00_mesh/Mesh500/mergedPointMesh500m.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.remove(temp_file)\n",
    "#os.remove(aimFolder + \"/temp/temp_file_0008.tif\")\n",
    "\n",
    "#os.rmdir(aimFolder + \"\\\\temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nppExtraction(year, aimFolder, coords_extration):\n",
    "    # this is to extract npp of each eyar of each mesh point\n",
    "    rasterFile = rasterio.open(aimFolder + \"/temp/temp_file_\" + str(year) + \"0004.tif\")\n",
    "    rasterArray = rasterFile.read(1)\n",
    "\n",
    "    valueArray = []\n",
    "    for point in coords_extration['geometry']:\n",
    "        x = point.xy[0][0]\n",
    "        y = point.xy[1][0]\n",
    "        row, col = rasterFile.index(x, y)\n",
    "        valueArray.append(rasterArray[row, col])\n",
    "        \n",
    "    valueArray = np.array(valueArray)\n",
    "    coords_extration['NPP_'+str(year)] = valueArray\n",
    "\n",
    "    rasterFile = None\n",
    "    return coords_extration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "aimFolder = \"F:/17_Article/01_Data/02_NetPrimaryProductivity\"\n",
    "coords_extration = gpd.read_file(\"F:/17_Article/01_Data/00_mesh/Mesh500/mergedPointMesh500m.shp\")\n",
    "nppResult = Parallel(n_jobs=4)(delayed(nppExtraction)(int(year), aimFolder, coords_extration) for year in np.linspace(2001, 2020, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "nppResult_2001 = nppResult[0]\n",
    "nppResult_2002 = nppResult[1]\n",
    "nppResult_2003 = nppResult[2]\n",
    "nppResult_2004 = nppResult[3]\n",
    "nppResult_2005 = nppResult[4]\n",
    "nppResult_2006 = nppResult[5]\n",
    "nppResult_2007 = nppResult[6]\n",
    "nppResult_2008 = nppResult[7]\n",
    "nppResult_2009 = nppResult[8]\n",
    "nppResult_2010 = nppResult[9]\n",
    "nppResult_2011 = nppResult[10]\n",
    "nppResult_2012 = nppResult[11]\n",
    "nppResult_2013 = nppResult[12]\n",
    "nppResult_2014 = nppResult[13]\n",
    "nppResult_2015 = nppResult[14]\n",
    "nppResult_2016 = nppResult[15]\n",
    "nppResult_2017 = nppResult[16]\n",
    "nppResult_2018 = nppResult[17]\n",
    "nppResult_2019 = nppResult[18]\n",
    "nppResult_2020 = nppResult[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "nppResult_2001['year'] = 2001\n",
    "nppResult_2002['year'] = 2002\n",
    "nppResult_2003['year'] = 2003\n",
    "nppResult_2004['year'] = 2004\n",
    "nppResult_2005['year'] = 2005\n",
    "nppResult_2006['year'] = 2006\n",
    "nppResult_2007['year'] = 2007\n",
    "nppResult_2008['year'] = 2008\n",
    "nppResult_2009['year'] = 2009\n",
    "nppResult_2010['year'] = 2010\n",
    "nppResult_2011['year'] = 2011\n",
    "nppResult_2012['year'] = 2012\n",
    "nppResult_2013['year'] = 2013\n",
    "nppResult_2014['year'] = 2014\n",
    "nppResult_2015['year'] = 2015\n",
    "nppResult_2016['year'] = 2016\n",
    "nppResult_2017['year'] = 2017\n",
    "nppResult_2018['year'] = 2018\n",
    "nppResult_2019['year'] = 2019\n",
    "nppResult_2020['year'] = 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "nppResult_2001 = pd.DataFrame(nppResult_2001.drop(columns='geometry'))\n",
    "nppResult_2002 = pd.DataFrame(nppResult_2002.drop(columns='geometry'))\n",
    "nppResult_2003 = pd.DataFrame(nppResult_2003.drop(columns='geometry'))\n",
    "nppResult_2004 = pd.DataFrame(nppResult_2004.drop(columns='geometry'))\n",
    "nppResult_2005 = pd.DataFrame(nppResult_2005.drop(columns='geometry'))\n",
    "nppResult_2006 = pd.DataFrame(nppResult_2006.drop(columns='geometry'))\n",
    "nppResult_2007 = pd.DataFrame(nppResult_2007.drop(columns='geometry'))\n",
    "nppResult_2008 = pd.DataFrame(nppResult_2008.drop(columns='geometry'))\n",
    "nppResult_2009 = pd.DataFrame(nppResult_2009.drop(columns='geometry'))\n",
    "nppResult_2010 = pd.DataFrame(nppResult_2010.drop(columns='geometry'))\n",
    "nppResult_2011 = pd.DataFrame(nppResult_2011.drop(columns='geometry'))\n",
    "nppResult_2012 = pd.DataFrame(nppResult_2012.drop(columns='geometry'))\n",
    "nppResult_2013 = pd.DataFrame(nppResult_2013.drop(columns='geometry'))\n",
    "nppResult_2014 = pd.DataFrame(nppResult_2014.drop(columns='geometry'))\n",
    "nppResult_2015 = pd.DataFrame(nppResult_2015.drop(columns='geometry'))\n",
    "nppResult_2016 = pd.DataFrame(nppResult_2016.drop(columns='geometry'))\n",
    "nppResult_2017 = pd.DataFrame(nppResult_2017.drop(columns='geometry'))\n",
    "nppResult_2018 = pd.DataFrame(nppResult_2018.drop(columns='geometry'))\n",
    "nppResult_2019 = pd.DataFrame(nppResult_2019.drop(columns='geometry'))\n",
    "nppResult_2020 = pd.DataFrame(nppResult_2020.drop(columns='geometry'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['G04c_001', 'NPP_2001', 'year'], dtype='object')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nppResult_2001.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "nppResult_2001.columns = ['G04c_001', 'NPP', 'year']\n",
    "nppResult_2002.columns = ['G04c_001', 'NPP', 'year']\n",
    "nppResult_2003.columns = ['G04c_001', 'NPP', 'year']\n",
    "nppResult_2004.columns = ['G04c_001', 'NPP', 'year']\n",
    "nppResult_2005.columns = ['G04c_001', 'NPP', 'year']\n",
    "nppResult_2006.columns = ['G04c_001', 'NPP', 'year']\n",
    "nppResult_2007.columns = ['G04c_001', 'NPP', 'year']\n",
    "nppResult_2008.columns = ['G04c_001', 'NPP', 'year']\n",
    "nppResult_2009.columns = ['G04c_001', 'NPP', 'year']\n",
    "nppResult_2010.columns = ['G04c_001', 'NPP', 'year']\n",
    "nppResult_2011.columns = ['G04c_001', 'NPP', 'year']\n",
    "nppResult_2012.columns = ['G04c_001', 'NPP', 'year']\n",
    "nppResult_2013.columns = ['G04c_001', 'NPP', 'year']\n",
    "nppResult_2014.columns = ['G04c_001', 'NPP', 'year']\n",
    "nppResult_2015.columns = ['G04c_001', 'NPP', 'year']\n",
    "nppResult_2016.columns = ['G04c_001', 'NPP', 'year']\n",
    "nppResult_2017.columns = ['G04c_001', 'NPP', 'year']\n",
    "nppResult_2018.columns = ['G04c_001', 'NPP', 'year']\n",
    "nppResult_2019.columns = ['G04c_001', 'NPP', 'year']\n",
    "nppResult_2020.columns = ['G04c_001', 'NPP', 'year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6733.1787\n",
      "6954.568\n",
      "6699.3506\n",
      "6941.993\n",
      "6611.0015\n",
      "6508.4023\n",
      "7125.2705\n",
      "7066.6777\n",
      "7038.5234\n",
      "6502.153\n",
      "6573.422\n",
      "6718.171\n",
      "6813.1533\n",
      "7084.9976\n",
      "7307.392\n",
      "7093.5884\n",
      "7038.908\n",
      "7051.997\n",
      "7239.1533\n",
      "7185.7896\n"
     ]
    }
   ],
   "source": [
    "print(nppResult_2001[\"NPP\"].mean())\n",
    "print(nppResult_2002[\"NPP\"].mean())\n",
    "print(nppResult_2003[\"NPP\"].mean())\n",
    "print(nppResult_2004[\"NPP\"].mean())\n",
    "print(nppResult_2005[\"NPP\"].mean())\n",
    "print(nppResult_2006[\"NPP\"].mean())\n",
    "print(nppResult_2007[\"NPP\"].mean())\n",
    "print(nppResult_2008[\"NPP\"].mean())\n",
    "print(nppResult_2009[\"NPP\"].mean())\n",
    "print(nppResult_2010[\"NPP\"].mean())\n",
    "print(nppResult_2011[\"NPP\"].mean())\n",
    "print(nppResult_2012[\"NPP\"].mean())\n",
    "print(nppResult_2013[\"NPP\"].mean())\n",
    "print(nppResult_2014[\"NPP\"].mean())\n",
    "print(nppResult_2015[\"NPP\"].mean())\n",
    "print(nppResult_2016[\"NPP\"].mean())\n",
    "print(nppResult_2017[\"NPP\"].mean())\n",
    "print(nppResult_2018[\"NPP\"].mean())\n",
    "print(nppResult_2019[\"NPP\"].mean())\n",
    "print(nppResult_2020[\"NPP\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "longNppDF = pd.concat(\n",
    "    [nppResult_2001, nppResult_2002, nppResult_2003, nppResult_2004, nppResult_2005, nppResult_2006, nppResult_2007, nppResult_2008,\n",
    "    nppResult_2009, nppResult_2010, nppResult_2011, nppResult_2012, nppResult_2013, nppResult_2014, nppResult_2015, nppResult_2016,\n",
    "    nppResult_2017, nppResult_2018, nppResult_2019, nppResult_2020]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del nppResult_2001\n",
    "del nppResult_2002\n",
    "del nppResult_2003\n",
    "del nppResult_2004\n",
    "del nppResult_2005\n",
    "del nppResult_2006\n",
    "del nppResult_2007\n",
    "del nppResult_2008\n",
    "del nppResult_2009\n",
    "del nppResult_2010\n",
    "del nppResult_2011\n",
    "del nppResult_2012\n",
    "del nppResult_2013\n",
    "del nppResult_2014\n",
    "del nppResult_2015\n",
    "del nppResult_2016\n",
    "del nppResult_2017\n",
    "del nppResult_2018\n",
    "del nppResult_2019\n",
    "del nppResult_2020\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NPP    6914.380371\n",
       "dtype: float32"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longNppDF = longNppDF.set_index(['G04c_001','year'])\n",
    "longNppDF.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileList = glob.glob(aimFolder + \"/temp/*.tif\")\n",
    "for filename in fileList:\n",
    "    os.remove(filename)\n",
    "\n",
    "os.rmdir(aimFolder + \"\\\\temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>NPP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G04c_001</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>303660001</th>\n",
       "      <th>2001</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303660002</th>\n",
       "      <th>2001</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303660003</th>\n",
       "      <th>2001</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303660004</th>\n",
       "      <th>2001</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303660011</th>\n",
       "      <th>2001</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                NPP\n",
       "G04c_001  year     \n",
       "303660001 2001  0.0\n",
       "303660002 2001  0.0\n",
       "303660003 2001  0.0\n",
       "303660004 2001  0.0\n",
       "303660011 2001  0.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longNppDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NTL extraction\n",
    "Night Time Light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import glob\n",
    "import rasterio\n",
    "from osgeo import gdal\n",
    "import geopandas as gpd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aimFolder = \"F:\\\\17_Article\\\\01_Data\\\\03_NTL_VIIRS\"\n",
    "os.mkdir(aimFolder + \"\\\\temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ntlExtraction(year, aimFolder, coords_extration):\n",
    "    #This funciton is try to extract ntl\n",
    "    #filename = aimFolder + \"\\\\\" + str(year) + \".zip\"\n",
    "    #with zipfile.ZipFile(filename, \"r\") as zip_ref:\n",
    "    #    zip_ref.extractall(aimFolder + \"\\\\temp\")\n",
    "    aimRaster = glob.glob(aimFolder + \"\\\\temp\\\\*\" + str(year) + \".tif\")\n",
    "    aimRaster = aimRaster[0]\n",
    "    rasterFile = rasterio.open(aimRaster)\n",
    "    rasterArray = rasterFile.read(1)\n",
    "    valueArray = []\n",
    "    for point in coords_extration['geometry']:\n",
    "        x = point.xy[0][0]\n",
    "        y = point.xy[1][0]\n",
    "        row, col = rasterFile.index(x, y)\n",
    "        valueArray.append(rasterArray[row, col])\n",
    "    \n",
    "    valueArray = np.array(valueArray)\n",
    "    coords_extration['NTL_'+str(year)] = valueArray\n",
    "    return coords_extration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "ntlResult = Parallel(n_jobs=2)(delayed(ntlExtraction)(int(year), aimFolder, coords_extration) for year in np.linspace(2002, 2020, 19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntlResult_2001 = ntlExtraction(int(2001), aimFolder, coords_extration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntlResult_2002 = ntlResult[0]\n",
    "ntlResult_2003 = ntlResult[1]\n",
    "ntlResult_2004 = ntlResult[2]\n",
    "ntlResult_2005 = ntlResult[3]\n",
    "ntlResult_2006 = ntlResult[4]\n",
    "ntlResult_2007 = ntlResult[5]\n",
    "ntlResult_2008 = ntlResult[6]\n",
    "ntlResult_2009 = ntlResult[7]\n",
    "ntlResult_2010 = ntlResult[8]\n",
    "ntlResult_2011 = ntlResult[9]\n",
    "ntlResult_2012 = ntlResult[10]\n",
    "ntlResult_2013 = ntlResult[11]\n",
    "ntlResult_2014 = ntlResult[12]\n",
    "ntlResult_2015 = ntlResult[13]\n",
    "ntlResult_2016 = ntlResult[14]\n",
    "ntlResult_2017 = ntlResult[15]\n",
    "ntlResult_2018 = ntlResult[16]\n",
    "ntlResult_2019 = ntlResult[17]\n",
    "ntlResult_2020 = ntlResult[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntlResult_2001['year'] = 2001\n",
    "ntlResult_2002['year'] = 2002\n",
    "ntlResult_2003['year'] = 2003\n",
    "ntlResult_2004['year'] = 2004\n",
    "ntlResult_2005['year'] = 2005\n",
    "ntlResult_2006['year'] = 2006\n",
    "ntlResult_2007['year'] = 2007\n",
    "ntlResult_2008['year'] = 2008\n",
    "ntlResult_2009['year'] = 2009\n",
    "ntlResult_2010['year'] = 2010\n",
    "ntlResult_2011['year'] = 2011\n",
    "ntlResult_2012['year'] = 2012\n",
    "ntlResult_2013['year'] = 2013\n",
    "ntlResult_2014['year'] = 2014\n",
    "ntlResult_2015['year'] = 2015\n",
    "ntlResult_2016['year'] = 2016\n",
    "ntlResult_2017['year'] = 2017\n",
    "ntlResult_2018['year'] = 2018\n",
    "ntlResult_2019['year'] = 2019\n",
    "ntlResult_2020['year'] = 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntlResult_2001 = pd.DataFrame(ntlResult_2001.drop(columns='geometry'))\n",
    "ntlResult_2002 = pd.DataFrame(ntlResult_2002.drop(columns='geometry'))\n",
    "ntlResult_2003 = pd.DataFrame(ntlResult_2003.drop(columns='geometry'))\n",
    "ntlResult_2004 = pd.DataFrame(ntlResult_2004.drop(columns='geometry'))\n",
    "ntlResult_2005 = pd.DataFrame(ntlResult_2005.drop(columns='geometry'))\n",
    "ntlResult_2006 = pd.DataFrame(ntlResult_2006.drop(columns='geometry'))\n",
    "ntlResult_2007 = pd.DataFrame(ntlResult_2007.drop(columns='geometry'))\n",
    "ntlResult_2008 = pd.DataFrame(ntlResult_2008.drop(columns='geometry'))\n",
    "ntlResult_2009 = pd.DataFrame(ntlResult_2009.drop(columns='geometry'))\n",
    "ntlResult_2010 = pd.DataFrame(ntlResult_2010.drop(columns='geometry'))\n",
    "ntlResult_2011 = pd.DataFrame(ntlResult_2011.drop(columns='geometry'))\n",
    "ntlResult_2012 = pd.DataFrame(ntlResult_2012.drop(columns='geometry'))\n",
    "ntlResult_2013 = pd.DataFrame(ntlResult_2013.drop(columns='geometry'))\n",
    "ntlResult_2014 = pd.DataFrame(ntlResult_2014.drop(columns='geometry'))\n",
    "ntlResult_2015 = pd.DataFrame(ntlResult_2015.drop(columns='geometry'))\n",
    "ntlResult_2016 = pd.DataFrame(ntlResult_2016.drop(columns='geometry'))\n",
    "ntlResult_2017 = pd.DataFrame(ntlResult_2017.drop(columns='geometry'))\n",
    "ntlResult_2018 = pd.DataFrame(ntlResult_2018.drop(columns='geometry'))\n",
    "ntlResult_2019 = pd.DataFrame(ntlResult_2019.drop(columns='geometry'))\n",
    "ntlResult_2020 = pd.DataFrame(ntlResult_2020.drop(columns='geometry'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['G04c_001', 'NTL_2001', 'year'], dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntlResult_2001.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntlResult_2001.columns = ['G04c_001', 'NTL', 'year']\n",
    "ntlResult_2002.columns = ['G04c_001', 'NTL', 'year']\n",
    "ntlResult_2003.columns = ['G04c_001', 'NTL', 'year']\n",
    "ntlResult_2004.columns = ['G04c_001', 'NTL', 'year']\n",
    "ntlResult_2005.columns = ['G04c_001', 'NTL', 'year']\n",
    "ntlResult_2006.columns = ['G04c_001', 'NTL', 'year']\n",
    "ntlResult_2007.columns = ['G04c_001', 'NTL', 'year']\n",
    "ntlResult_2008.columns = ['G04c_001', 'NTL', 'year']\n",
    "ntlResult_2009.columns = ['G04c_001', 'NTL', 'year']\n",
    "ntlResult_2010.columns = ['G04c_001', 'NTL', 'year']\n",
    "ntlResult_2011.columns = ['G04c_001', 'NTL', 'year']\n",
    "ntlResult_2012.columns = ['G04c_001', 'NTL', 'year']\n",
    "ntlResult_2013.columns = ['G04c_001', 'NTL', 'year']\n",
    "ntlResult_2014.columns = ['G04c_001', 'NTL', 'year']\n",
    "ntlResult_2015.columns = ['G04c_001', 'NTL', 'year']\n",
    "ntlResult_2016.columns = ['G04c_001', 'NTL', 'year']\n",
    "ntlResult_2017.columns = ['G04c_001', 'NTL', 'year']\n",
    "ntlResult_2018.columns = ['G04c_001', 'NTL', 'year']\n",
    "ntlResult_2019.columns = ['G04c_001', 'NTL', 'year']\n",
    "ntlResult_2020.columns = ['G04c_001', 'NTL', 'year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\li.chao.987@s.kyushu-u.ac.jp\\AppData\\Local\\Temp\\ipykernel_12728\\1752473119.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ntlResult_2020.NTL[ntlResult_2020[\"NTL\"]<0] = 0\n",
      "C:\\Users\\li.chao.987@s.kyushu-u.ac.jp\\AppData\\Local\\Temp\\ipykernel_12728\\1752473119.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ntlResult_2019.NTL[ntlResult_2019[\"NTL\"]<0] = 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1114916"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntlResult_2020.NTL[ntlResult_2020[\"NTL\"]<0] = 0\n",
    "ntlResult_2020[\"NTL\"].mean()\n",
    "ntlResult_2019.NTL[ntlResult_2019[\"NTL\"]<0] = 0\n",
    "ntlResult_2019[\"NTL\"].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6480222\n",
      "1.6131924\n",
      "1.4684126\n",
      "1.2629389\n",
      "1.5879596\n",
      "1.575272\n",
      "1.6215699\n",
      "1.4386377\n",
      "1.3462512\n",
      "1.0992323\n",
      "1.3615805\n",
      "1.3009588\n",
      "1.061045\n",
      "1.0638536\n",
      "1.0337858\n",
      "1.0159932\n",
      "1.1423855\n",
      "1.1576278\n",
      "1.1114916\n",
      "1.0489889\n"
     ]
    }
   ],
   "source": [
    "print(ntlResult_2001[\"NTL\"].mean())\n",
    "print(ntlResult_2002[\"NTL\"].mean())\n",
    "print(ntlResult_2003[\"NTL\"].mean())\n",
    "print(ntlResult_2004[\"NTL\"].mean())\n",
    "print(ntlResult_2005[\"NTL\"].mean())\n",
    "print(ntlResult_2006[\"NTL\"].mean())\n",
    "print(ntlResult_2007[\"NTL\"].mean())\n",
    "print(ntlResult_2008[\"NTL\"].mean())\n",
    "print(ntlResult_2009[\"NTL\"].mean())\n",
    "print(ntlResult_2010[\"NTL\"].mean())\n",
    "print(ntlResult_2011[\"NTL\"].mean())\n",
    "print(ntlResult_2012[\"NTL\"].mean())\n",
    "print(ntlResult_2013[\"NTL\"].mean())\n",
    "print(ntlResult_2014[\"NTL\"].mean())\n",
    "print(ntlResult_2015[\"NTL\"].mean())\n",
    "print(ntlResult_2016[\"NTL\"].mean())\n",
    "print(ntlResult_2017[\"NTL\"].mean())\n",
    "print(ntlResult_2018[\"NTL\"].mean())\n",
    "print(ntlResult_2019[\"NTL\"].mean())\n",
    "print(ntlResult_2020[\"NTL\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "longNtlDF = pd.concat(\n",
    "    [ntlResult_2001, ntlResult_2002, ntlResult_2003, ntlResult_2004, ntlResult_2005, ntlResult_2006, ntlResult_2007, ntlResult_2008,\n",
    "    ntlResult_2009, ntlResult_2010, ntlResult_2011, ntlResult_2012, ntlResult_2013, ntlResult_2014, ntlResult_2015, ntlResult_2016,\n",
    "    ntlResult_2017, ntlResult_2018, ntlResult_2019, ntlResult_2020]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del ntlResult_2001\n",
    "del ntlResult_2002\n",
    "del ntlResult_2003\n",
    "del ntlResult_2004\n",
    "del ntlResult_2005\n",
    "del ntlResult_2006\n",
    "del ntlResult_2007\n",
    "del ntlResult_2008\n",
    "del ntlResult_2009\n",
    "del ntlResult_2010\n",
    "del ntlResult_2011\n",
    "del ntlResult_2012\n",
    "del ntlResult_2013\n",
    "del ntlResult_2014\n",
    "del ntlResult_2015\n",
    "del ntlResult_2016\n",
    "del ntlResult_2017\n",
    "del ntlResult_2018\n",
    "del ntlResult_2019\n",
    "del ntlResult_2020\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>NTL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G04c_001</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>303660001</th>\n",
       "      <th>2001</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303660002</th>\n",
       "      <th>2001</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303660003</th>\n",
       "      <th>2001</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303660004</th>\n",
       "      <th>2001</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303660011</th>\n",
       "      <th>2001</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                NTL\n",
       "G04c_001  year     \n",
       "303660001 2001  0.0\n",
       "303660002 2001  0.0\n",
       "303660003 2001  0.0\n",
       "303660004 2001  0.0\n",
       "303660011 2001  0.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longNtlDF = longNtlDF.set_index(['G04c_001','year'])\n",
    "longNtlDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NTL    1.297961\n",
       "dtype: float32"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "longNtlDF.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del ntlResult\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] 另一个程序正在使用此文件，进程无法访问。: 'F:\\\\17_Article\\\\01_Data\\\\03_NTL_VIIRS\\\\temp\\\\LongNTL_2001.tif'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12728\\1943968306.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#fileList = fileList[1:]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfileList\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#os.rmdir(aimFolder + \"\\\\temp\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] 另一个程序正在使用此文件，进程无法访问。: 'F:\\\\17_Article\\\\01_Data\\\\03_NTL_VIIRS\\\\temp\\\\LongNTL_2001.tif'"
     ]
    }
   ],
   "source": [
    "fileList = glob.glob(aimFolder + \"\\\\temp\\\\*\")\n",
    "#fileList = fileList[1:]\n",
    "for filename in fileList:\n",
    "    os.remove(filename)\n",
    "\n",
    "#os.rmdir(aimFolder + \"\\\\temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rmdir(aimFolder + \"\\\\temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>NTL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G04c_001</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>303660001</th>\n",
       "      <th>2001</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303660002</th>\n",
       "      <th>2001</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303660003</th>\n",
       "      <th>2001</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303660004</th>\n",
       "      <th>2001</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303660011</th>\n",
       "      <th>2001</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                NTL\n",
       "G04c_001  year     \n",
       "303660001 2001  0.0\n",
       "303660002 2001  0.0\n",
       "303660003 2001  0.0\n",
       "303660004 2001  0.0\n",
       "303660011 2001  0.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longNtlDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature Extraction\n",
    "Surf_Temp_8Days_1Km (M*D11A2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "get_ipython().magic('reset -sf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import gc\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "aimFolder = \"F:\\\\17_Article\\\\01_Data\\\\08_Temperature\\\\Surf_Temp_8Days_1Km_v6\"\n",
    "os.mkdir(aimFolder + \"\\\\temp\")\n",
    "#year = 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dayTimeTemperatureRaster(year, aimFolder):\n",
    "### Day time Temp\n",
    "    dayTimeTemperatureFileList = glob.glob(aimFolder + \"\\\\LST_Day_1km\\\\M*\" + str(year) + \"*.tif\")\n",
    "\n",
    "    dayTimeTemperatureRasterList = []\n",
    "    for dayTimeTemperatureFile in dayTimeTemperatureFileList:\n",
    "        dayTimeTemperatureRasterRaw = gdal.Open(dayTimeTemperatureFile, gdal.GA_ReadOnly)\n",
    "        dayTimeTemperatureRaster = dayTimeTemperatureRasterRaw.ReadAsArray()\n",
    "        dayTimeTemperatureRasterRaw = None\n",
    "        dayTimeTemperatureRaster = dayTimeTemperatureRaster.astype(\"float\")\n",
    "        dayTimeTemperatureRaster[dayTimeTemperatureRaster == 0] = np.nan\n",
    "        dayTimeTemperatureRaster = dayTimeTemperatureRaster * 0.02 - 273.16\n",
    "        dayTimeTemperatureRasterList.append(dayTimeTemperatureRaster)\n",
    "\n",
    "    meanDayTimeTemperatureRaster = np.nanmean(dayTimeTemperatureRasterList, axis = 0)\n",
    "    stdDayTimeTemperatureRaster = np.nanstd(dayTimeTemperatureRasterList, axis = 0)\n",
    "    dayTimeTemperatureRasterList = None\n",
    "    gc.collect()\n",
    "\n",
    "    src_dataset = gdal.Open(dayTimeTemperatureFileList[0], gdal.GA_ReadOnly)\n",
    "    geotransform = src_dataset.GetGeoTransform()\n",
    "    spatialreference = src_dataset.GetProjection()\n",
    "    ncol = meanDayTimeTemperatureRaster.shape[1]\n",
    "    nrow = meanDayTimeTemperatureRaster.shape[0]\n",
    "    nband = 1\n",
    "    src_dataset = None\n",
    "\n",
    "    # write the tif files\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    dst_dataset = driver.Create(aimFolder + \"\\\\temp\\\\\" + str(year) + \"_daytime_mean.tif\", ncol, nrow, nband, gdal.GDT_Float32) \n",
    "    #### ^^^^^ Change this line\n",
    "    dst_dataset.SetGeoTransform(geotransform)\n",
    "    dst_dataset.SetProjection(spatialreference)\n",
    "    dst_dataset.GetRasterBand(1).WriteArray(meanDayTimeTemperatureRaster)\n",
    "    dst_dataset = None\n",
    "\n",
    "    # write the tif files\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    dst_dataset = driver.Create(aimFolder + \"\\\\temp\\\\\" + str(year) + \"_daytime_std.tif\", ncol, nrow, nband, gdal.GDT_Float32) \n",
    "    #### ^^^^^ Change this line\n",
    "    dst_dataset.SetGeoTransform(geotransform)\n",
    "    dst_dataset.SetProjection(spatialreference)\n",
    "    dst_dataset.GetRasterBand(1).WriteArray(stdDayTimeTemperatureRaster)\n",
    "    dst_dataset = None\n",
    "\n",
    "    ### resample and reproject\n",
    "    raster_rprj = gdal.Warp(aimFolder + \"\\\\temp\\\\\" + str(year) + \"_daytime_mean_re.tif\", \n",
    "                            aimFolder + \"\\\\temp\\\\\" + str(year) + \"_daytime_mean.tif\", dstSRS = \"EPSG:4326\",\n",
    "                            xRes = 0.008, yRes = 0.008, resampleAlg = \"average\", srcNodata = math.nan)\n",
    "    raster_rprj = None\n",
    "\n",
    "    raster_rprj = gdal.Warp(aimFolder + \"\\\\temp\\\\\" + str(year) + \"_daytime_std_re.tif\", \n",
    "                            aimFolder + \"\\\\temp\\\\\" + str(year) + \"_daytime_std.tif\", dstSRS = \"EPSG:4326\",\n",
    "                            xRes = 0.008, yRes = 0.008, resampleAlg = \"average\", srcNodata = math.nan)\n",
    "    raster_rprj = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\li.chao.987@s.kyushu-u.ac.jp\\AppData\\Local\\Temp\\ipykernel_12728\\1949070710.py:15: RuntimeWarning: Mean of empty slice\n",
      "  meanDayTimeTemperatureRaster = np.nanmean(dayTimeTemperatureRasterList, axis = 0)\n",
      "d:\\Anaconda3\\envs\\Usegdal\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "#Parallel(n_jobs=2)(delayed(dayTimeTemperatureRaster)(int(year), aimFolder) for year in np.linspace(2001, 2020, 20))\n",
    "#parallel unavailable\n",
    "\n",
    "for year in np.linspace(2003, 2020, 18):\n",
    "    dayTimeTemperatureRaster(int(year), aimFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nightTimeTemperatureRaster(year, aimFolder):\n",
    "    ### Night time Temp\n",
    "    nightTimeTemperatureFileList = glob.glob(aimFolder + \"\\\\LST_Night_1km\\\\M*\" + str(year) + \"*.tif\")\n",
    "\n",
    "    nightTimeTemperatureRasterList = []\n",
    "    for nightTimeTemperatureFile in nightTimeTemperatureFileList:\n",
    "        nightTimeTemperatureRasterRaw = gdal.Open(nightTimeTemperatureFile, gdal.GA_ReadOnly)\n",
    "        nightTimeTemperatureRaster = nightTimeTemperatureRasterRaw.ReadAsArray()\n",
    "        nightTimeTemperatureRasterRaw = None\n",
    "        nightTimeTemperatureRaster = nightTimeTemperatureRaster.astype(\"float\")\n",
    "        nightTimeTemperatureRaster[nightTimeTemperatureRaster == 0] = np.nan\n",
    "        nightTimeTemperatureRaster = nightTimeTemperatureRaster * 0.02 - 273.16\n",
    "        nightTimeTemperatureRasterList.append(nightTimeTemperatureRaster)\n",
    "\n",
    "    meanNightTimeTemperatureRaster = np.nanmean(nightTimeTemperatureRasterList, axis = 0)\n",
    "    stdNightTimeTemperatureRaster = np.nanstd(nightTimeTemperatureRasterList, axis = 0)\n",
    "    nightTimeTemperatureRasterList = None\n",
    "    gc.collect()\n",
    "\n",
    "    src_dataset = gdal.Open(nightTimeTemperatureFileList[0], gdal.GA_ReadOnly)\n",
    "    geotransform = src_dataset.GetGeoTransform()\n",
    "    spatialreference = src_dataset.GetProjection()\n",
    "    ncol = meanNightTimeTemperatureRaster.shape[1]\n",
    "    nrow = meanNightTimeTemperatureRaster.shape[0]\n",
    "    nband = 1\n",
    "    src_dataset = None\n",
    "\n",
    "    # write the tif files\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    dst_dataset = driver.Create(aimFolder + \"\\\\temp\\\\\" + str(year) + \"_nighttime_mean.tif\", ncol, nrow, nband, gdal.GDT_Float32) \n",
    "    #### ^^^^^ Change this line\n",
    "    dst_dataset.SetGeoTransform(geotransform)\n",
    "    dst_dataset.SetProjection(spatialreference)\n",
    "    dst_dataset.GetRasterBand(1).WriteArray(meanNightTimeTemperatureRaster)\n",
    "    dst_dataset = None\n",
    "\n",
    "    # write the tif files\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    dst_dataset = driver.Create(aimFolder + \"\\\\temp\\\\\" + str(year) + \"_nighttime_std.tif\", ncol, nrow, nband, gdal.GDT_Float32) \n",
    "    #### ^^^^^ Change this line\n",
    "    dst_dataset.SetGeoTransform(geotransform)\n",
    "    dst_dataset.SetProjection(spatialreference)\n",
    "    dst_dataset.GetRasterBand(1).WriteArray(stdNightTimeTemperatureRaster)\n",
    "    dst_dataset = None\n",
    "\n",
    "    ### resample and reproject\n",
    "    raster_rprj = gdal.Warp(aimFolder + \"\\\\temp\\\\\" + str(year) + \"_nighttime_mean_re.tif\", \n",
    "                            aimFolder + \"\\\\temp\\\\\" + str(year) + \"_nighttime_mean.tif\", dstSRS = \"EPSG:4326\",\n",
    "                            xRes = 0.008, yRes = 0.008, resampleAlg = \"average\", srcNodata = math.nan)\n",
    "    raster_rprj = None\n",
    "\n",
    "    raster_rprj = gdal.Warp(aimFolder + \"\\\\temp\\\\\" + str(year) + \"_nighttime_std_re.tif\", \n",
    "                            aimFolder + \"\\\\temp\\\\\" + str(year) + \"_nighttime_std.tif\", dstSRS = \"EPSG:4326\",\n",
    "                            xRes = 0.008, yRes = 0.008, resampleAlg = \"average\", srcNodata = math.nan)\n",
    "    raster_rprj = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\li.chao.987@s.kyushu-u.ac.jp\\AppData\\Local\\Temp\\ipykernel_12728\\342181939.py:15: RuntimeWarning: Mean of empty slice\n",
      "  meanNightTimeTemperatureRaster = np.nanmean(nightTimeTemperatureRasterList, axis = 0)\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "for year in np.linspace(2001, 2020, 20):\n",
    "    nightTimeTemperatureRaster(int(year), aimFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_extration = gpd.read_file(\"F:/17_Article/01_Data/00_mesh/Mesh500/mergedPointMesh500m.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordExtractionFromRaster(RasterName, GeoPandasDataFrame, NewColumnName):\n",
    "    rasterFile = rasterio.open(RasterName)\n",
    "    coords_extration = GeoPandasDataFrame.copy()\n",
    "    rasterArray = rasterFile.read(1)\n",
    "    \n",
    "    valueArray = []\n",
    "    for point in coords_extration['geometry']:\n",
    "        x = point.xy[0][0]\n",
    "        y = point.xy[1][0]\n",
    "        row, col = rasterFile.index(x, y)\n",
    "        valueArray.append(rasterArray[row, col])\n",
    "        \n",
    "    valueArray = np.array(valueArray)\n",
    "    coords_extration[NewColumnName] = valueArray\n",
    "    rasterFile = None\n",
    "    return coords_extration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "dayTimeTempMeanResult = Parallel(n_jobs=8)(delayed(coordExtractionFromRaster)(aimFolder + \"\\\\temp\\\\\" + str(int(year)) + \"_daytime_mean_re.tif\", coords_extration, 'dayTimeMeanTemp') for year in np.linspace(2001, 2020, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['G04c_001', 'geometry', 'dayTimeMeanTemp'], dtype='object')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dayTimeTempMeanResult[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeParallelDf(DF):\n",
    "    singleDF_0 = DF[0]\n",
    "    singleDF_1 = DF[1]\n",
    "    singleDF_2 = DF[2]\n",
    "    singleDF_3 = DF[3]\n",
    "    singleDF_4 = DF[4]\n",
    "    singleDF_5 = DF[5]\n",
    "    singleDF_6 = DF[6]\n",
    "    singleDF_7 = DF[7]\n",
    "    singleDF_8 = DF[8]\n",
    "    singleDF_9 = DF[9]\n",
    "    singleDF_10 = DF[10]\n",
    "    singleDF_11 = DF[11]\n",
    "    singleDF_12 = DF[12]\n",
    "    singleDF_13 = DF[13]\n",
    "    singleDF_14 = DF[14]\n",
    "    singleDF_15 = DF[15]\n",
    "    singleDF_16 = DF[16]\n",
    "    singleDF_17 = DF[17]\n",
    "    singleDF_18 = DF[18]\n",
    "    singleDF_19 = DF[19]\n",
    "\n",
    "    singleDF_0['year'] = 2001\n",
    "    singleDF_1['year'] = 2002 \n",
    "    singleDF_2['year'] = 2003 \n",
    "    singleDF_3['year'] = 2004 \n",
    "    singleDF_4['year'] = 2005 \n",
    "    singleDF_5['year'] = 2006 \n",
    "    singleDF_6['year'] = 2007 \n",
    "    singleDF_7['year'] = 2008 \n",
    "    singleDF_8['year'] = 2009 \n",
    "    singleDF_9['year'] = 2010 \n",
    "    singleDF_10['year'] = 2011\n",
    "    singleDF_11['year'] = 2012 \n",
    "    singleDF_12['year'] = 2013 \n",
    "    singleDF_13['year'] = 2014 \n",
    "    singleDF_14['year'] = 2015 \n",
    "    singleDF_15['year'] = 2016 \n",
    "    singleDF_16['year'] = 2017 \n",
    "    singleDF_17['year'] = 2018 \n",
    "    singleDF_18['year'] = 2019 \n",
    "    singleDF_19['year'] = 2020\n",
    "\n",
    "    mergeDF = pd.concat([\n",
    "        singleDF_0, singleDF_1, singleDF_2, singleDF_3, singleDF_4, singleDF_5, singleDF_6, singleDF_7, singleDF_8, singleDF_9,\n",
    "        singleDF_10, singleDF_11, singleDF_12, singleDF_13, singleDF_14, singleDF_15, singleDF_16, singleDF_17, singleDF_18, singleDF_19\n",
    "    ])\n",
    "\n",
    "    return mergeDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mergeDayTimeTempMeanResult = mergeParallelDf(dayTimeTempMeanResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['G04c_001', 'geometry', 'dayTimeMeanTemp', 'year'], dtype='object')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergeDayTimeTempMeanResult.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeDayTimeTempMeanResult = pd.DataFrame(mergeDayTimeTempMeanResult.drop(columns='geometry'))\n",
    "mergeDayTimeTempMeanResult = mergeDayTimeTempMeanResult[['G04c_001', 'dayTimeMeanTemp', 'year']]\n",
    "mergeDayTimeTempMeanResult = mergeDayTimeTempMeanResult.set_index(['G04c_001', 'year'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1278"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del dayTimeTempMeanResult\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "dayTimeTempStdResult = Parallel(n_jobs=8)(delayed(coordExtractionFromRaster)(aimFolder + \"\\\\temp\\\\\" + str(int(year)) + \"_daytime_std_re.tif\", coords_extration, 'dayTimeStdTemp') for year in np.linspace(2001, 2020, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeDayTimeTempStdResult = mergeParallelDf(dayTimeTempStdResult)\n",
    "mergeDayTimeTempStdResult = pd.DataFrame(mergeDayTimeTempStdResult.drop(columns='geometry'))\n",
    "mergeDayTimeTempStdResult = mergeDayTimeTempStdResult[['G04c_001', 'dayTimeStdTemp', 'year']]\n",
    "mergeDayTimeTempStdResult = mergeDayTimeTempStdResult.set_index(['G04c_001', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dayTimeStdTemp    9.443231\n",
       "dtype: float32"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergeDayTimeTempStdResult.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "523921"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergeDayTimeTempMeanResult['dayTimeMeanTemp'].isna().count() - mergeDayTimeTempMeanResult['dayTimeMeanTemp'].count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26241"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dayTimeTempStdResult[0]['dayTimeStdTemp'].isna().count() - dayTimeTempStdResult[0]['dayTimeStdTemp'].count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1553024"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dayTimeTempStdResult[0]['dayTimeStdTemp'].isna().count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DatasetReader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12728\\4228134513.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrasterFile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"F:\\17_Article\\01_Data\\08_Temperature\\Surf_Temp_8Days_1Km_v6\\temp\\2001_daytime_mean.tif\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrasterFile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrasterFile\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mrasterArray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrasterFile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m139.878\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m35.860\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrasterFile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DatasetReader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "rasterFile = rasterio.open(r\"F:\\17_Article\\01_Data\\08_Temperature\\Surf_Temp_8Days_1Km_v6\\temp\\2001_daytime_mean.tif\")\n",
    "rasterFile = rasterFile[::-1,:]\n",
    "rasterArray = rasterFile.read(1)\n",
    "x, y = 139.878, 35.860\n",
    "row, col = rasterFile.index(x, y)\n",
    "print(row, col)\n",
    "#print(rasterArray[row, col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G04c_001</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>303660001</td>\n",
       "      <td>POINT (136.00313 20.50208)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>303660002</td>\n",
       "      <td>POINT (136.00937 20.50208)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>303660003</td>\n",
       "      <td>POINT (136.00313 20.50625)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>303660004</td>\n",
       "      <td>POINT (136.00937 20.50625)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>303660011</td>\n",
       "      <td>POINT (136.01562 20.50208)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    G04c_001                    geometry\n",
       "0  303660001  POINT (136.00313 20.50208)\n",
       "1  303660002  POINT (136.00937 20.50208)\n",
       "2  303660003  POINT (136.00313 20.50625)\n",
       "3  303660004  POINT (136.00937 20.50625)\n",
       "4  303660011  POINT (136.01562 20.50208)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords_extration.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge and Save Out\n",
    "now includes longNtlResult and longNppResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "longFinalDf = pd.concat([longNtlDF, longNppDF])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "longFinalDf.to_pickle(\"F:/17_Article/01_Data/98_20yearPickles/02_NtlNppPrecTemp.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "longFinalDf = pd.read_pickle(\"F:/17_Article/01_Data/98_20yearPickles/02_NtlNppPrecTemp.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NTL    31060480\n",
       "NPP           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longFinalDf[pd.isna(longFinalDf.NPP)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NTL           0\n",
       "NPP    31060160\n",
       "dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longFinalDf[pd.isna(longFinalDf.NTL)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62120960, 2)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longFinalDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>NTL</th>\n",
       "      <th>NPP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G04c_001</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>303660001</th>\n",
       "      <th>2001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303660002</th>\n",
       "      <th>2001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303660003</th>\n",
       "      <th>2001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303660004</th>\n",
       "      <th>2001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303660011</th>\n",
       "      <th>2001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                NTL  NPP\n",
       "G04c_001  year          \n",
       "303660001 2001  0.0  NaN\n",
       "303660002 2001  0.0  NaN\n",
       "303660003 2001  0.0  NaN\n",
       "303660004 2001  0.0  NaN\n",
       "303660011 2001  0.0  NaN"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longFinalDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('Usegdal')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3fc66252abba36e085bb3ec14543b1917131014ad56a966409ac5ee82f8d6ab9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
